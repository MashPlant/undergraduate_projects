课程安排是前八周上课+后八周project，今年和去年都不存在选择project这种事情，只给了一个project做。两年都是在树莓派上，都是使用摄像头，去年好像是识别人的石头剪刀布的动作，今年是用摄像头正对屏幕上的图像的一部分进行拍摄，计算拍摄到的部分位于原图像的实时位置。感觉今年这个简单不少，去年怎么也得用点AI的技术，今年这个调调OpenCV就完事了。

主要的难点应该是用Buildroot裁剪出一个能运行识别程序且尽量小的树莓派Linux系统，用到一些OS课相关的技术，至少我是这么觉得的。但也没说非得这样裁剪，助教提供了一个Python写的识别程序，我猜测（不负任何责任）即使只是把它在完整的Linux系统上跑起来也能及格，这应该不需要任何工作量。

代码见：https://github.com/MashPlant/rpi-image-locating。识别部分确实只调了OpenCV，但把整个系统裁剪到了8.1MiB。
